{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40d2be79",
   "metadata": {},
   "source": [
    "# Taylor Swift Lyric Generation with RNN-LSTM\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Run the cells in sequential order \n",
    "\n",
    "The data link to dataset - https://www.kaggle.com/datasets/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums\n",
    "\n",
    "The Taylor Swift Song Lyrics dataset on Kaggle is a collection of song lyrics from all of Taylor Swift's albums, including her debut album released in 2006 up to her latest album at the time of the dataset creation. The dataset includes lyrics from all of the songs on each album, including deluxe editions and bonus tracks. The dataset is provided in CSV format and includes columns for the album, song name, lyrics, and the year of release. It is intended to be used for natural language processing tasks, such as training language models or sentiment analysis, or for exploring patterns and trends in Taylor Swift's songwriting over time.\n",
    "\n",
    "Here, we train a RNN-LSTM model. We train the model on this dataset and generate sentences which are then checked for quality.\n",
    "\n",
    "Steps performed -\n",
    "\n",
    "1) Dataset parsing\n",
    "\n",
    "2) Tokenization, removal of special charactors, <s> </s> addition, /n addition\n",
    "\n",
    "3) Corpus generation which is fed for training\n",
    "\n",
    "4) Creating a RNN-LSTM model and training while monitoring accuracy\n",
    "\n",
    "5) Generation\n",
    "\n",
    "6) Perplexity calculation\n",
    "\n",
    "## To get started\n",
    "Download the dataset and put it in `Dataset/taylorswift` folder.\n",
    "\n",
    "Run the cells\n",
    "\n",
    "----------------------------------------\n",
    "Contributed by - Samanvya Tripathi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf1537",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db33e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import string\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "sns.set_palette(sns.color_palette('tab20', 20))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f460b8",
   "metadata": {},
   "source": [
    "# Build the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d0e81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def take(n, iterable):\n",
    "    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "class LanguageModelRNN:\n",
    "    def __init__(self, MIN_FREQUENCY=3, MIN_SEQ=5, BATCH_SIZE=32):\n",
    "        \"\"\"\n",
    "        init function to define all the variables\n",
    "        Paramters:\n",
    "        MIN_FREQUENCY: The frequency of tokens below which the tokens are ignored\n",
    "        MIN_SEQ: Number of words per sentence to be generated\n",
    "        BATCH_SIZE: Batch size for training the model\n",
    "        \"\"\"\n",
    "        self.MIN_FREQUENCY = MIN_FREQUENCY\n",
    "        self.MIN_SEQ = MIN_SEQ\n",
    "        self.BATCH_SIZE =  BATCH_SIZE\n",
    "        \n",
    "        self.data_train = []\n",
    "        self.lyric_dic = {}\n",
    "        self.lyric_dic_processed = {}\n",
    "        \n",
    "        self.text_as_list = []\n",
    "        self.frequencies = {}\n",
    "        self.uncommon_words = set()\n",
    "        self.words = set()\n",
    "        self.word_count = 0\n",
    "        self.valid_seqs = []\n",
    "        self.end_seq_words = []\n",
    "        self.num_words = 0\n",
    "        self.word_indices = {}\n",
    "        self.indices_word = {}\n",
    "        \n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        self.examples_file = \"\"\n",
    "        self.model = \"\"\n",
    "        self.history = \"\"\n",
    "    \n",
    "    def load_dataset(self, link_to_dataset_train):\n",
    "        \"\"\"Load the dataset into class variable\n",
    "        Parameters:\n",
    "          link_to_dataset_train: the path where the dataset is present\n",
    "        \"\"\"\n",
    "        # Dataset loading\n",
    "        self.data_train = pd.read_csv(link_to_dataset_train, encoding='windows-1252')\n",
    "        print(self.data_train.head(20))\n",
    "        \n",
    "    def dataset_parsing(self):\n",
    "        \"\"\"cleaning the data and making it usefull for the model\n",
    "        Apply processing, adding to <s> </s> and /n to last words of every sentence\n",
    "        \"\"\"\n",
    "        # Parsing dataset and organising\n",
    "        lyric_dic = {} # song name to lyrics\n",
    "        corpus = []\n",
    "        data = self.data_train\n",
    "        prev = data[\"track_title\"][0] \n",
    "        temp = []\n",
    "        \n",
    "        for index, rows in data.iterrows():\n",
    "            corpus.append(rows[\"lyric\"])\n",
    "            if prev == rows[\"track_title\"]:\n",
    "                temp.append(rows[\"lyric\"])\n",
    "            else:\n",
    "                lyric_dic[prev] = temp\n",
    "                prev = rows[\"track_title\"]\n",
    "                temp = []\n",
    "                temp.append(rows[\"lyric\"])\n",
    "        self.lyric_dic = lyric_dic\n",
    "        self.corpus = corpus\n",
    "        #print(lyric_dic.keys())\n",
    "        #print(corpus)\n",
    "        \n",
    "        lyric_dic_processed = {}\n",
    "        for song in lyric_dic:\n",
    "            t_songs = []\n",
    "            for lyrics in lyric_dic[song]:\n",
    "                t_words = []\n",
    "                t_songs.append(self.preprocess_text(lyrics))\n",
    "            lyric_dic_processed[song] = t_songs\n",
    "        self.lyric_dic_processed = lyric_dic_processed\n",
    "        print(\"Cleaned dataset\")\n",
    "        n_items = take(1, lyric_dic_processed.items())\n",
    "        print(n_items)\n",
    "        \n",
    "        # ------------------------------\n",
    "        self.extract_text()\n",
    "        \n",
    "        #-----------------------------\n",
    "        for w in self.text_as_list:\n",
    "            self.frequencies[w] = self.frequencies.get(w, 0) + 1  \n",
    "        #print(self.frequencies)\n",
    "        \n",
    "        self.uncommon_words = set([key for key in self.frequencies.keys() if self.frequencies[key] < self.MIN_FREQUENCY])\n",
    "        self.words = sorted(set([key for key in self.frequencies.keys() if self.frequencies[key] >= self.MIN_FREQUENCY]))\n",
    "        \n",
    "        self.num_words = len(self.words)\n",
    "        self.word_indices = dict((w, i) for i, w in enumerate(self.words))\n",
    "        self.indices_word = dict((i, w) for i, w in enumerate(self.words))\n",
    "        \n",
    "        for i in range(len(self.text_as_list) - self.MIN_SEQ ):\n",
    "            end_slice = i + self.MIN_SEQ + 1\n",
    "            if len( set(self.text_as_list[i:end_slice]).intersection(self.uncommon_words) ) == 0:\n",
    "                self.valid_seqs.append(self.text_as_list[i: i + self.MIN_SEQ])\n",
    "                self.end_seq_words.append(self.text_as_list[i + self.MIN_SEQ])\n",
    "        \n",
    "        print(\"\\nSpliting into train and test\")\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.valid_seqs, self.end_seq_words, test_size=0.02, random_state=42)\n",
    "        print(\"Train {} \\n \\n Test {}\".format(self.X_train[0:10], self.X_test[0:10]))\n",
    "        \n",
    "    def display_stats(self):\n",
    "        \"\"\"\n",
    "        Displaying stats of the dataset\n",
    "        \"\"\"\n",
    "        print(\"Total Words \", self.word_count)\n",
    "        print('Words with less than {} appearances: {}'.format( self.MIN_FREQUENCY, len(self.uncommon_words)))\n",
    "        print('Words with more than {} appearances: {}'.format( self.MIN_FREQUENCY, len(self.words)))\n",
    "        print('Valid sequences of size {}: {}'.format(self.MIN_SEQ, len(self.valid_seqs)))\n",
    "        \n",
    "    \n",
    "    def generator(self, sentence_list, next_word_list, batch_size):\n",
    "        \"\"\"Generate RNN data for fit and evaluation\n",
    "        \"\"\"\n",
    "        index = 0\n",
    "        while True:\n",
    "            x = np.zeros((batch_size, self.MIN_SEQ), dtype=np.int32)\n",
    "            y = np.zeros((batch_size), dtype=np.int32)\n",
    "            for i in range(batch_size):\n",
    "                for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n",
    "                    x[i, t] = self.word_indices[w]\n",
    "                y[i] = self.word_indices[next_word_list[index % len(sentence_list)]]\n",
    "                index = index + 1\n",
    "            yield x, y\n",
    "\n",
    "    def sample(self, preds, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Helper function to sample an index from a probability array\n",
    "        \"\"\"\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        \"\"\"\n",
    "        Function invoked at end of each epoch. Prints generated text.\n",
    "        \"\"\"\n",
    "        examples_file = self.examples_file\n",
    "        examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n",
    "        seed_index = np.random.randint(len(self.X_train+self.X_test))\n",
    "        seed = (self.X_train+self.X_test)[seed_index]\n",
    "\n",
    "        for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "            sentence = seed\n",
    "            examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n",
    "            examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n",
    "            examples_file.write(' '.join(sentence))\n",
    "\n",
    "            for i in range(50):\n",
    "                x_pred = np.zeros((1, self.MIN_SEQ))\n",
    "                for t, word in enumerate(sentence):\n",
    "                    x_pred[0, t] = self.word_indices[word]\n",
    "                preds = self.model.predict(x_pred, verbose=0)[0]\n",
    "                next_index = self.sample(preds, diversity)\n",
    "                next_word = self.indices_word[next_index]\n",
    "                sentence = sentence[1:]\n",
    "                sentence.append(next_word)\n",
    "                examples_file.write(\" \"+next_word)\n",
    "            examples_file.write('\\n')\n",
    "        examples_file.write('='*80 + '\\n')\n",
    "        examples_file.flush()\n",
    "        \n",
    "    def get_model(self):\n",
    "        \"\"\"\n",
    "        Function to build the RNN model\n",
    "        \"\"\"\n",
    "        print('Build model...')\n",
    "        model = Sequential()\n",
    "        # using a Bidirectional LSTM with an Embedding layer before it\n",
    "        model.add(Embedding(input_dim=len(self.words), output_dim=1024))\n",
    "        model.add(Bidirectional(LSTM(128)))\n",
    "        # Output is a a softmax activation the size of the vocab to\n",
    "        # get the next word generated based on the input sequence\n",
    "        model.add(Dense(len(self.words)))\n",
    "        model.add(Activation('softmax'))\n",
    "        return model\n",
    "    \n",
    "    def train(self, epochs, loss, optimizer):\n",
    "        \"\"\"\n",
    "        Function to build train the model\n",
    "        \"\"\"\n",
    "        m = self.get_model()\n",
    "        m.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "        self.model = m\n",
    "        \n",
    "        print_callback = LambdaCallback(on_epoch_end=self.on_epoch_end)\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "        callbacks_list = [print_callback]\n",
    "        self.examples_file = open('examples-RNN.txt', \"w\")\n",
    "        \n",
    "        # fitting the model with the given hyper-parameters and callbacks\n",
    "        # history is stored in a self contained variable\n",
    "        self.history = m.fit(model.generator(model.X_train, model.y_train, model.BATCH_SIZE),\n",
    "                   steps_per_epoch=int(len(model.valid_seqs)/model.BATCH_SIZE) + 1,\n",
    "                   epochs=epochs,\n",
    "                   callbacks=callbacks_list,\n",
    "                   validation_data=model.generator(model.X_test, model.y_train, model.BATCH_SIZE),\n",
    "                   validation_steps=int(len(model.y_train)/model.BATCH_SIZE) + 1)\n",
    "        \n",
    "    \n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        wrapper function to print our language model's summary\n",
    "        \"\"\"\n",
    "        print(self.model.summary())\n",
    "    \n",
    "    # -----------------------------------------\n",
    "    # helpers\n",
    "    def preprocess_text(self, text):\n",
    "        # lower case\n",
    "        preprocessed = text.lower()\n",
    "\n",
    "        # punctuation removal\n",
    "        def remove_punctuation(text):\n",
    "            punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
    "            return punctuationfree\n",
    "        preprocessed = remove_punctuation(preprocessed)\n",
    "\n",
    "        # stop work removal\n",
    "        def remove_stopwords(text):\n",
    "            text = text.split()\n",
    "            output= [i for i in text if i not in stopwords]\n",
    "            final = \"\"\n",
    "            for i in output:\n",
    "                final+=i + \" \"\n",
    "            return final[:len(final)-2]\n",
    "        #preprocessed = remove_stopwords(preprocessed)\n",
    "        return preprocessed\n",
    "    \n",
    "    def extract_text(self):\n",
    "        word_count = 0\n",
    "        for song_name in self.lyric_dic_processed:\n",
    "            for sen in self.lyric_dic_processed[song_name]:\n",
    "                t = sen.split(\" \")\n",
    "                for w in t:\n",
    "                    self.text_as_list.append(w)\n",
    "                    word_count+=1\n",
    "        self.word_count = word_count\n",
    "        #print(self.text_as_list)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69fc22f9",
   "metadata": {},
   "source": [
    "## Define the model \n",
    "We initialize the model object with a minimum required word frequency of 3, a sequence length of 7 (for preparing the training data) and batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2385db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LanguageModelRNN(MIN_FREQUENCY=3, MIN_SEQ=7, BATCH_SIZE=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ef526b",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce3b5ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          artist         album track_title  track_n  \\\n",
      "0   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "1   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "2   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "3   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "4   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "5   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "6   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "7   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "8   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "9   Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "10  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "11  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "12  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "13  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "14  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "15  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "16  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "17  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "18  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "19  Taylor Swift  Taylor Swift  Tim McGraw        1   \n",
      "\n",
      "                                                lyric  line  year  \n",
      "0                 He said the way my blue eyes shined     1  2006  \n",
      "1         Put those Georgia stars to shame that night     2  2006  \n",
      "2                              I said, \"That's a lie\"     3  2006  \n",
      "3                         Just a boy in a Chevy truck     4  2006  \n",
      "4                That had a tendency of gettin' stuck     5  2006  \n",
      "5                               On backroads at night     6  2006  \n",
      "6    And I was right there beside him all summer long     7  2006  \n",
      "7   And then the time we woke up to find that summ...     8  2006  \n",
      "8                       But when you think Tim McGraw     9  2006  \n",
      "9                   I hope you think my favorite song    10  2006  \n",
      "10                The one we danced to all night long    11  2006  \n",
      "11              The moon like a spotlight on the lake    12  2006  \n",
      "12                           When you think happiness    13  2006  \n",
      "13           I hope you think that little black dress    14  2006  \n",
      "14                     Think of my head on your chest    15  2006  \n",
      "15                        And my old faded blue jeans    16  2006  \n",
      "16                          When you think Tim McGraw    17  2006  \n",
      "17                             I hope you think of me    18  2006  \n",
      "18                     September saw a month of tears    19  2006  \n",
      "19             And thankin' God that you weren't here    20  2006  \n"
     ]
    }
   ],
   "source": [
    "model.load_dataset(\"Dataset/taylorswift/train - RNN.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1470a8a5",
   "metadata": {},
   "source": [
    "## Dataset Parsing\n",
    "This method helps with cleaning the data and preparing it for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50931c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset\n",
      "[('Tim McGraw', ['he said the way my blue eyes shined', 'put those georgia stars to shame that night', 'i said thats a lie', 'just a boy in a chevy truck', 'that had a tendency of gettin stuck', 'on backroads at night', 'and i was right there beside him all summer long', 'and then the time we woke up to find that summer gone', 'but when you think tim mcgraw', 'i hope you think my favorite song', 'the one we danced to all night long', 'the moon like a spotlight on the lake', 'when you think happiness', 'i hope you think that little black dress', 'think of my head on your chest', 'and my old faded blue jeans', 'when you think tim mcgraw', 'i hope you think of me', 'september saw a month of tears', 'and thankin god that you werent here', 'to see me like that', 'but in a box beneath my bed', 'is a letter that you never read', 'from three summers back', 'its hard not to find it all a little bittersweet', 'and lookin back on all of that its nice to believe', 'when you think tim mcgraw', 'i hope you think my favorite song', 'the one we danced to all night long', 'the moon like a spotlight on the lake', 'when you think happiness', 'i hope you think that little black dress', 'think of my head on your chest', 'and my old faded blue jeans', 'when you think tim mcgraw', 'i hope you think of me', 'and im back for the first time since then', 'im standin on your street', 'and theres a letter left on your doorstep', 'and the first thing that youll read is', 'when you think tim mcgraw', 'i hope you think my favorite song', 'someday youll turn your radio on', 'i hope it takes you back to that place', 'when you think happiness', 'i hope you think that little black dress', 'think of my head on your chest', 'and my old faded blue jeans', 'when you think tim mcgraw', 'i hope you think of me', 'oh think of me', 'mmmm', 'he said the way my blue eyes shine', 'put those georgia stars to shame that night', 'i said thats a lie'])]\n",
      "\n",
      "Spliting into train and test\n",
      "Train [['of', 'my', 'day', 'im', 'taking', 'pictures', 'in'], ['cause', 'we', 'never', 'go', 'out', 'of', 'style'], ['way', 'but', 'what', 'can', 'i', 'say', 'youre'], ['to', 'show', 'you', 'she', 'dont', 'even', 'know'], ['sitting', 'by', 'the', 'water', 'and', 'every', 'time'], ['it', 'on', 'the', 'way', 'home', 'way', 'home'], ['so', 'green', 'i', 'know', 'places', 'and', 'i'], ['keep', 'singing', 'dont', 'know', 'why', 'i', 'do'], ['at', 'things', 'that', 'shine', 'and', 'life', 'makes'], ['swallowing', 'my', 'pride', 'standing', 'in', 'front', 'of']] \n",
      " \n",
      " Test [['new', 'romantics', 'come', 'on', 'come', 'along', 'with'], ['wish', 'you', 'knew', 'that', 'i', 'miss', 'you'], ['into', 'things', 'didnt', 'you', 'flash', 'your', 'green'], ['and', 'ever', 'broke', 'your', 'heart', 'ill', 'put'], ['i', 'did', 'something', 'bad', 'whys', 'it', 'feel'], ['i', 'see', 'sparks', 'fly', 'whenever', 'you', 'smile'], ['everybody', 'knows', 'that', 'i', 'see', 'you', 'turn'], ['for', 'better', 'i', 'would', 'wait', 'forever', 'and'], ['believed', 'in', 'you', 'its', 'alright', 'just', 'wait'], ['marvelous', 'tune', 'it', 'was', 'the', 'best', 'night']]\n"
     ]
    }
   ],
   "source": [
    "model.dataset_parsing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "330f8ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 1024)        1123328   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 256)              1180672   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1097)              281929    \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1097)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,585,929\n",
      "Trainable params: 2,585,929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = model.get_model()\n",
    "x.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0be3306",
   "metadata": {},
   "source": [
    "## Display Dataset Stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c3e0ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words  34881\n",
      "Words with less than 3 appearances: 1302\n",
      "Words with more than 3 appearances: 1097\n",
      "Valid sequences of size 7: 25694\n"
     ]
    }
   ],
   "source": [
    "model.display_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ae7fcf9",
   "metadata": {},
   "source": [
    "## Training \n",
    "Here we train the model for 20 epochs, with a sparse categorical cross-entropy loss and adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58c08a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Epoch 1/20\n",
      "803/803 [==============================] - 189s 227ms/step - loss: 5.1492 - accuracy: 0.1176 - val_loss: 6.4299 - val_accuracy: 0.0233\n",
      "Epoch 2/20\n",
      "803/803 [==============================] - 166s 206ms/step - loss: 3.5423 - accuracy: 0.3186 - val_loss: 7.3231 - val_accuracy: 0.0078\n",
      "Epoch 3/20\n",
      "803/803 [==============================] - 144s 180ms/step - loss: 2.4510 - accuracy: 0.5048 - val_loss: 8.0179 - val_accuracy: 0.0117\n",
      "Epoch 4/20\n",
      "803/803 [==============================] - 156s 195ms/step - loss: 1.7263 - accuracy: 0.6437 - val_loss: 8.6632 - val_accuracy: 0.0097\n",
      "Epoch 5/20\n",
      "803/803 [==============================] - 198s 247ms/step - loss: 1.2303 - accuracy: 0.7414 - val_loss: 9.2082 - val_accuracy: 0.0097\n",
      "Epoch 6/20\n",
      "803/803 [==============================] - 164s 205ms/step - loss: 0.8699 - accuracy: 0.8187 - val_loss: 9.7837 - val_accuracy: 0.0117\n",
      "Epoch 7/20\n",
      "803/803 [==============================] - 155s 193ms/step - loss: 0.6068 - accuracy: 0.8783 - val_loss: 10.3575 - val_accuracy: 0.0117\n",
      "Epoch 8/20\n",
      "803/803 [==============================] - 201s 251ms/step - loss: 0.4194 - accuracy: 0.9213 - val_loss: 10.8832 - val_accuracy: 0.0097\n",
      "Epoch 9/20\n",
      "803/803 [==============================] - 199s 248ms/step - loss: 0.3030 - accuracy: 0.9442 - val_loss: 11.3575 - val_accuracy: 0.0136\n",
      "Epoch 10/20\n",
      "803/803 [==============================] - 165s 206ms/step - loss: 0.2361 - accuracy: 0.9562 - val_loss: 11.8085 - val_accuracy: 0.0136\n",
      "Epoch 11/20\n",
      "803/803 [==============================] - 201s 250ms/step - loss: 0.2024 - accuracy: 0.9599 - val_loss: 12.1474 - val_accuracy: 0.0136\n",
      "Epoch 12/20\n",
      "803/803 [==============================] - 201s 251ms/step - loss: 0.1856 - accuracy: 0.9607 - val_loss: 12.4224 - val_accuracy: 0.0117\n",
      "Epoch 13/20\n",
      "803/803 [==============================] - 184s 230ms/step - loss: 0.1742 - accuracy: 0.9612 - val_loss: 12.6963 - val_accuracy: 0.0136\n",
      "Epoch 14/20\n",
      "803/803 [==============================] - 183s 228ms/step - loss: 0.1658 - accuracy: 0.9618 - val_loss: 12.9807 - val_accuracy: 0.0117\n",
      "Epoch 15/20\n",
      "803/803 [==============================] - 188s 235ms/step - loss: 0.1593 - accuracy: 0.9614 - val_loss: 13.3070 - val_accuracy: 0.0097\n",
      "Epoch 16/20\n",
      "803/803 [==============================] - 192s 240ms/step - loss: 0.1592 - accuracy: 0.9605 - val_loss: 13.4534 - val_accuracy: 0.0117\n",
      "Epoch 17/20\n",
      "803/803 [==============================] - 175s 218ms/step - loss: 0.1569 - accuracy: 0.9602 - val_loss: 13.6995 - val_accuracy: 0.0117\n",
      "Epoch 18/20\n",
      "803/803 [==============================] - 194s 242ms/step - loss: 0.1513 - accuracy: 0.9610 - val_loss: 13.8613 - val_accuracy: 0.0117\n",
      "Epoch 19/20\n",
      "803/803 [==============================] - 168s 210ms/step - loss: 0.1448 - accuracy: 0.9619 - val_loss: 14.0873 - val_accuracy: 0.0117\n",
      "Epoch 20/20\n",
      "803/803 [==============================] - 204s 254ms/step - loss: 0.1433 - accuracy: 0.9610 - val_loss: 14.1785 - val_accuracy: 0.0136\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=20, loss='sparse_categorical_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae545e88",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9c9c178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEWCAYAAABsY4yMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAwqklEQVR4nO3deXwU5f3A8c83N0kI9x0gIFHkSsCoyCXBC/BAvC0K1LMeBW+xaqVaW6Vq1apt8QKpVWoRvMAqQgQB0SCHXApo+BHkiCA5gIQcz++PmYQlbJINZHb2+L5fr3nt7Mwz83x3dvPdJ8/MPiPGGJRSSoWeCLcDUEop5QxN8EopFaI0wSulVIjSBK+UUiFKE7xSSoUoTfBKKRWiNMGrehOReSIyrqHL1jOGoSKS29D79QcRmSYif3Q7DhX6otwOQPmHiBR5PI0HSoBy+/nNxpg3fd2XMWaEE2WVUg1LE3yYMMYkVs6LSA5wgzFmfvVyIhJljCnzZ2wqcOj7H1q0iybMVXZ1iMj9IrITeF1EmonIhyKSJyK/2PPJHttkicgN9vx4EflCRJ6yy/4oIiOOsWwXEVkkIoUiMl9EXhSRf/n4Ok6269onIutE5CKPdSNFZL293+0ico+9vKX92vaJyF4RWSwiXv8mROQ5EdkmIgUiskJEBnusmywi/xGRN+w61olIhsf6viLyjb1uJhBXy+s4QUQWiMgeEflZRN4UkaYe6zuKyLv2e7NHRF7wWHejiGyw61kvIv3s5UZEunmUq+oiOsb3v7mIvC4iP9nr59jL14rIhR7lou3XkF7rm6ccowleAbQFmgOdgZuwPhev2887AQeBF2rcGk4HvgNaAlOAV0VEjqHsv4GvgBbAZOBaX4IXkWjgA+AToDXwW+BNETnJLvIqVjdUY6AXsMBefjeQC7QC2gC/A2oau+NrIB3rOP0beEdEPBP1RcDbQFPgfezjJSIxwBxghr3tO8Cltb0c4M9Ae+BkoCPWsUBEIoEPga1ACtDBrhMRudwuNxZIsuPZU0s9nur7/s/A6ubriXW8/2ovfwO4xqPcSGCHMWaVj3GohmaM0SnMJiAHONueHwocAuJqKZ8O/OLxPAuriwdgPLDZY108VpJsW5+yWImkDIj3WP8v4F81xDQUyLXnBwM7gQiP9W8Bk+35/wNuBpKq7eNR4D2g2zEcw1+ANHt+MjDfY10P4KA9PwT4CRCP9UuBP/pYz8XASnv+DCAPiPJS7n/AxBr2YTxfIzCtsv76vv9AO6ACaOalXHugsPI4A/8F7nP78x7Ok7bgFUCeMaa48omIxIvIP0Vkq4gUAIuApnYL0pudlTPGmAP2bGI9y7YH9nosA9jmY/ztgW3GmAqPZVuxWrhgtZhHAltF5HMROcNe/hdgM/CJiPwgIpNqqkBE7ra7P/JFZB/QBOu/kKNeF3AAiBORKDu27cbOeB6x1VRPaxF52+5KKsD6kquspyOw1XjvI+8IbKlpv3Woz/vfEet9+qX6TowxPwFLgEvtbqURgM8n71XD0wSv4OhuibuBk4DTjTFJWK1QsLoPnLIDaC4i8R7LOvq47U9Ax2r9552A7QDGmK+NMaOwuhPmAP+xlxcaY+42xnQFLgTuEpGzqu/c7m+/H7gCq+XaFMjHt+OxA+hQrcuqUy3l/4z1fvSxj/01HvVsAzrZXxzVbQNOqGGfB7D+W6rUttr6+rz/27Dep6Y11DXdjvlyYJkxZnsN5ZQfaIJX3jTG6nfdJyLNgUecrtAYsxXIBiaLSIzdyr6wjs0qLQf2A/fZJ/aG2tu+be9rjIg0McaUAgXYl4eKyAUi0s1OvpXLy73svzFW91EeECUiv8fq5/bFMnvbCSISJSKXAKfVUr4xUIR17DsA93qs+wrrC+MJEUkQkTgRGWivewW4R0ROEUs3Eelsr1sF/EpEIkVkOHBmHTHX+P4bY3YA84CX7JOx0SIyxGPbOUA/YCJWn7xykSZ45c2zQCPgZ+BL4GM/1TsGq595D/BHYCbW9fq1MsYcwjqpOAIr5peAscaYjXaRa4Ecu7vhNxw+EZgKzMdKqMuAl4wxWV6q+B9WUvseq3ulGB+7j+zYLsE6//ALcCXwbi2b/AErQeYDH3mWNcaUY31xdcM6r5Br7w9jzDvA41gngAuxEm1ze9OJ9nb7sI7xnDrCfpba3/9rgVJgI7AbuMMjxoPALKBLHa9T+YEc2TWoVOCwLyncaIxx/D8I1XDs/3BONMZcU2dh5ShtwauAISKn2teBR9hdCaOou7WpAojdpXM9MNXtWJQmeBVY2mJdVlkEPA/cYoxZ6WpEymciciNW19U8Y8wit+NR2kWjlFIhS1vwSikVogJqsLGWLVualJQUt8NQSqmgsWLFip+NMa28rQuoBJ+SkkJ2drbbYSilVNAQkRp/Ga1dNEopFaI0wSulVIjSBK+UUiEqoPrglVL1V1paSm5uLsXFxXUXVkErLi6O5ORkoqOjfd5GE7xSQS43N5fGjRuTkpJCzfdZUcHMGMOePXvIzc2lS5cuPm+nXTRKBbni4mJatGihyT2EiQgtWrSo939pmuCVCgGa3EPfsbzHQZ/gS8pKmLJkCp9u+dTtUJRSKqAEfYKPiYzhqaVPMWPNDLdDUSrs7Nmzh/T0dNLT02nbti0dOnSoen7o0KFat83OzmbChAl11jFgwIAGiTUrK4sLLrigQfYVLIL+JKuIMDRlKAtzFmKM0X9VlfKjFi1asGrVKgAmT55MYmIi99xzT9X6srIyoqK8p5mMjAwyMjLqrGPp0qUNEms4CvoWPEBmSia5Bbls+eVY7zmslGoo48eP56677iIzM5P777+fr776igEDBtC3b18GDBjAd999BxzZop48eTLXXXcdQ4cOpWvXrjz//PNV+0tMTKwqP3ToUC677DK6d+/OmDFjqBwNd+7cuXTv3p1BgwYxYcKEOlvqe/fu5eKLL6ZPnz7079+fNWvWAPD5559X/QfSt29fCgsL2bFjB0OGDCE9PZ1evXqxePHiBj9mTnG0BS8iOVi3DysHyowxdX9dH4PMLpkALPxxId2ad3OiCqWCwh0f38GqnasadJ/pbdN5dviz9drm+++/Z/78+URGRlJQUMCiRYuIiopi/vz5/O53v2PWrFlHbbNx40YWLlxIYWEhJ510ErfccstR13yvXLmSdevW0b59ewYOHMiSJUvIyMjg5ptvZtGiRXTp0oWrr766zvgeeeQR+vbty5w5c1iwYAFjx45l1apVPPXUU7z44osMHDiQoqIi4uLimDp1Kueddx4PPvgg5eXlHDhwoF7Hwk3+aMFnGmPSnUruACe1OIm2iW1ZmLPQqSqUUvVw+eWXExkZCUB+fj6XX345vXr14s4772TdunVetzn//POJjY2lZcuWtG7dml27dh1V5rTTTiM5OZmIiAjS09PJyclh48aNdO3ater6cF8S/BdffMG1114LwLBhw9izZw/5+fkMHDiQu+66i+eff559+/YRFRXFqaeeyuuvv87kyZP59ttvady48bEeFr8L+j54sPrhM1MytR9ehb36trSdkpCQUDX/8MMPk5mZyezZs8nJyWHo0KFet4mNja2aj4yMpKyszKcyx3LTIm/biAiTJk3i/PPPZ+7cufTv35/58+czZMgQFi1axEcffcS1117Lvffey9ixY+tdpxucbsEb4BMRWSEiN3krICI3iUi2iGTn5eUdc0WZKZnsLNrJd3u+O+Z9KKUaXn5+Ph06dABg2rRpDb7/7t2788MPP5CTkwPAzJkz69xmyJAhvPnmm4DVt9+yZUuSkpLYsmULvXv35v777ycjI4ONGzeydetWWrduzY033sj111/PN9980+CvwSlOJ/iBxph+wAjgNhEZUr2AMWaqMSbDGJPRqpXXMet94tkPr5QKHPfddx8PPPAAAwcOpLy8vMH336hRI1566SWGDx/OoEGDaNOmDU2aNKl1m8mTJ5OdnU2fPn2YNGkS06dPB+DZZ5+lV69epKWl0ahRI0aMGEFWVlbVSddZs2YxceLEBn8NTvHbPVlFZDJQZIx5qqYyGRkZ5lhv+GGModOznRjQcQAzL6v7G1ypULFhwwZOPvlkt8NwVVFREYmJiRhjuO2220hNTeXOO+90O6wG5+29FpEVNZ3jdKwFLyIJItK4ch44F1jrYH1kpmSSlZN1TH1ySqng9fLLL5Oenk7Pnj3Jz8/n5ptvdjukgODkSdY2wGz7hGcU8G9jzMcO1kdmSiYz1sxgfd56erbu6WRVSqkAcuedd4Zki/14OZbgjTE/AGlO7d+bqn74nIWa4JVSYS8kfslaKaVpCilNU/R6eKWUIsQSPFDVD19hKtwORSmlXBVyCX5oylD2HtzLt7u+dTsUpZRyVcgl+MyUw/3wSilnBdNwweEoJIYq8NSxSUdOaHYCC3MWckf/O9wOR6mQpsMFe1deXl41Fo+bQq4FD1Yr/vOczymvaPhfzSmlaheowwXn5OQwePBg+vXrR79+/Y744pgyZQq9e/cmLS2NSZMmAbB582bOPvts0tLS6NevH1u2bDnqpiG333571fALKSkpPProowwaNIh33nmHl19+mVNPPZW0tDQuvfTSqlEod+3axejRo0lLSyMtLY2lS5fy8MMP89xzz1Xt98EHHzziGByrkGvBg3W55CsrX2HVzlWc0v4Ut8NRym/uuAPsBnWDSU+HZ5+t3zaBOFxw69at+fTTT4mLi2PTpk1cffXVZGdnM2/ePObMmcPy5cuJj49n7969AIwZM4ZJkyYxevRoiouLqaioYNu2bbW+7ri4OL744gvA6r668cYbAXjooYd49dVX+e1vf8uECRM488wzmT17NuXl5RQVFdG+fXsuueQSJk6cSEVFBW+//TZfffVV/Q66F6GZ4D364TXBK+V/1YcLHjduHJs2bUJEKC0t9bpN5XDBsbGxVcMFJycnH1GmcrhgoGq44MTExKOGC546depR+y8tLeX2229n1apVREZG8v333wMwf/58fv3rXxMfHw9A8+bNKSwsZPv27YwePRqwErcvrrzyyqr5tWvX8tBDD7Fv3z6Kioo477zzAFiwYAFvvPEGYI2I2aRJE5o0aUKLFi1YuXIlu3btom/fvrRo0cKnOmsTkgm+XeN2nNTiJBbmLOSeAffUvYFSIaK+LW2nBOJwwX/9619p06YNq1evpqKioippextivKZ9RkVFUVFx+BLs4uLiI9Z7vu7x48czZ84c0tLSmDZtGllZWbXGd8MNNzBt2jR27tzJdddd59NrqktI9sGD1YpfvHUxZRVHf0iUUv4TKMMF5+fn065dOyIiIpgxY0bVyJbnnnsur732WlUf+d69e0lKSiI5OZk5c+YAUFJSwoEDB+jcuTPr16+npKSE/Px8PvvssxrjKiwspF27dpSWllYNTQxw1lln8fe//x2wTsYWFBQAMHr0aD7++GO+/vrrqtb+8QrdBN8lk8JDhaz4aYXboSgV1gJluOBbb72V6dOn079/f77//vuq1vbw4cO56KKLyMjIID09naeesga8nTFjBs8//zx9+vRhwIAB7Ny5k44dO3LFFVfQp08fxowZQ9++fWuM67HHHuP000/nnHPOoXv37lXLn3vuORYuXEjv3r055ZRTqu5wFRMTQ2ZmJldccUWDXYHjt+GCfXE8wwVXt3v/bto81YY/n/VnJg2a1CD7VCoQ6XDBoTFccEVFBf369eOdd94hNTXVa5mAGS7Yba0TWtOzVU/9wZNSYSDYhwtev3493bp146yzzqoxuR+LkDzJWikzJZPXVr3GofJDxETGuB2OUsohwT5ccI8ePfjhhx8afL8h24IHqx/+QOkBvt7+tduhKOWoQOpqVc44lvc4pBP8mZ3PRBDtplEhLS4ujj179miSD2HGGPbs2ePz9fiVQrqLpkV8C/q06UNWThYPDXnI7XCUckRycjK5ubnk5eW5HYpyUFxc3FE//KpLSCd4sPrh/7HiH5SUlRAbFVv3BkoFmejo6KpfcSrlKaS7aMDqhy8uK2b59uVuh6KUUn4V8gl+SOchREgEC3/UfnilVHgJ+QTfNK4pfdv21ROtSqmwE/IJHqx++GW5yzhYetDtUJRSym/CI8F3yeRQ+SGW5S5zOxSllPKbsEjwgzsNJlIitR9eKRVWwiLBN45tTEb7DO2HV0qFlbBI8GD1w3+1/Sv2H9rvdihKKeUXYZPgh6YMpbSilCXblrgdilJK+UXYJPiBnQYSFRGl/fBKqbARNgk+MSaR0zqcpv3wSqmwETYJHqx++OyfsiksKXQ7FKWUcpzjCV5EIkVkpYh86HRddclMyaTclLP4/xa7HYpSSjnOHy34icAGP9RTpwEdBxATGaP98EqpsOBogheRZOB84BUn6/FVo+hG9E/ur/3wSqmw4HQL/lngPqCipgIicpOIZItItj9uWJCZksnKnSvZV7zP8bqUUspNjiV4EbkA2G2MWVFbOWPMVGNMhjEmo1WrVk6FUyUzJZMKU8GirYscr0sppdzkZAt+IHCRiOQAbwPDRORfDtbnk/7J/YmLitN+eKVUyHMswRtjHjDGJBtjUoCrgAXGmGucqs9XsVGxDOg4QPvhlVIhL6yug6+UmZLJml1r2Htwr9uhKKWUY/yS4I0xWcaYC/xRly8yUzIxGD7P+dztUJRSyjFh2YI/tcOpxEfHazeNUiqkhWWCj4mMYVCnQZrglVIhLSwTPFjdNGt3ryVvv/PX3iullBvCOsEDZOVkuRuIUko5JGwT/CntT6FxTGPtplFKhaywTfBREVEM7jxYE7xSKmSFbYIHq5tm488b2VG4w+1QlFKqwYV9ggfth1dKhaawTvDpbdNpGtdUu2mUUiEprBN8ZEQkQzoP0QSvlApJYZ3gweqm2bx3M7kFuW6HopRSDUoTvN0Pr8MHK6VCTdgn+N5tetMqvhUfbnL9nuBKKdWgwj7BR0gEV/W6ivc2vscvB39xOxyllGowYZ/gAcanj6ekvISZ62a6HYpSSjUYTfBA37Z96d26N9NXT3c7FKWUajCa4AERYVzaOL7M/ZKNP290OxyllGoQmuBtY/qMIVIimb5KW/FKqdCgCd7WNrEtI1JHMGPNDMoryt0ORymljpsmeA/j0saxvXA7n/34mduhKKXUcdME7+HCEy+kWVwzpq2a5nYoSil13DTBe4iNiuVXvX/F7I2zyS/OdzscpZQ6LprgqxmXNo7ismL+s+4/boeilFLHRRN8NRntM+jRqgfTVk9zOxSllDoumuCrERHGp41n6balbNqzye1wlFLqmGmC9+KaPtcQIRH6y1alVFDTBO9Fu8btOO+E83hj9RtUmAq3w1FKqWOiCb4G49PHs61gm44Tr5QKWprga3DRSRfRNK6pnmxVSgUtTfA1iIuK46qeVzFr/SwKSgrcDkcppepNE3wtxqWP42DZQf67/r9uh6KUUvXmWIIXkTgR+UpEVovIOhH5g1N1OeX0DqdzUouTdOgCpVRQcrIFXwIMM8akAenAcBHp72B9DU5EGJ8+nsX/t5gte7e4HY5SStWLYwneWIrsp9H2ZJyqzynX9LkGQXhj9Rtuh6KUUvXiaB+8iESKyCpgN/CpMWa5lzI3iUi2iGTn5eU5Gc4xSU5K5pwTzmH66ul6TbxSKqg4muCNMeXGmHQgGThNRHp5KTPVGJNhjMlo1aqVk+Ecs/Fp49mav5VFWxe5HYpSSvnML1fRGGP2AVnAcH/U19Au7n4xSbFJerJVKRVUnLyKppWINLXnGwFnA0F5R+tG0Y24sueV/Hf9fyk6VFT3BkopFQCcbMG3AxaKyBrga6w++A8drM9R49PHs790P7PWz3I7FKWU8omTV9GsMcb0Ncb0Mcb0MsY86lRd/nBG8hmkNk/VoQuUUkHDpwQvIgkiEmHPnygiF4lItLOhBRYRYVzaOLJysvjxlx/dDkcpperkawt+ERAnIh2Az4BfA9OcCipQXZt2LYIwY80Mt0NRSqk6+ZrgxRhzALgE+JsxZjTQw7mwAlOnJp0Y1mUY01ZN02vilVIBz+cELyJnAGOAj+xlUc6EFNjGp4/nx30/8sX/feF2KEopVStfE/wdwAPAbGPMOhHpCoTlnTBGdx9N45jGTF+lt/NTSgU2nxK8MeZzY8xFxpgn7ZOtPxtjJjgcW0BKiEng8h6X85/1/2H/of1uh6OUUjXy9Sqaf4tIkogkAOuB70TkXmdDC1zj08dTdKiIdze863YoSilVI1+7aHoYYwqAi4G5QCfgWqeCCnSDOg2ia7OuTF+t3TRKqcDla4KPtq97vxh4zxhTShAO/dtQKq+JX/DjArbu2+p2OEop5ZWvCf6fQA6QACwSkc5AWN+odGzaWAxGr4lXSgUsX0+yPm+M6WCMGWnfyGMrkOlwbAEtpWkKmSmZTF89HWPC9p8ZpVQA8/UkaxMReabyxhwi8jRWaz6sjUsbx+a9m1m6banboSil1FF87aJ5DSgErrCnAuB1p4IKFpf2uJSE6AQdJ14pFZB8TfAnGGMeMcb8YE9/ALo6GVgwSIxJ5PKe1jXxB0oPuB2OUkodwdcEf1BEBlU+EZGBwEFnQgou49LGUVBSwOwNs90ORSmljuBrgv8N8KKI5IhIDvACcLNjUQWRIZ2HkNo8lSeWPEF5Rbnb4SilVBVfr6JZbYxJA/oAfYwxfYFhjkYWJCIkgifOfoK1u9fy2srX3A5HKaWq1OuOTsaYAvsXrQB3ORBPUBrdfTSDOw3moYUPUVhS6HY4SikFHN8t+6TBoghyIsIz5z3D7v27eeKLJ9wORymlgONL8PrrHg8Z7TO4ts+1PL3saR2+QCkVEGpN8CJSKCIFXqZCoL2fYgwajw97nAiJ4HcLfud2KEopVXuCN8Y0NsYkeZkaG2PC8o5OtenYpCP3DLiHf3/7b5bnLnc7HKVUmDueLhrlxX0D76NtYlvu+uQuHaNGKeUqTfANLDEmkceHPc7SbUt5Z/07boejlApjmuAdMC5tHGlt0rh//v0UlxW7HY5SKkxpgndAZEQkT5/7NDn7cnh++fNuh6OUClOa4B1yVtezuPDEC3l88ePs3r/b7XCUUmFIE7yDppwzhf2H9jM5a7LboSilwpAmeAd1b9mdWzJu4Z8r/sm63evcDkcpFWY0wTvskaGP0DimMfd+eq/boSilwoxjCV5EOorIQhHZICLrRGSiU3UFspbxLXl4yMPM2zyP/23+n9vhKKXCiJMt+DLgbmPMyUB/4DYR6eFgfQHr9tNup2uzrtz9yd2UVZS5HY5SKkw4luCNMTuMMd/Y84XABqCDU/UFstioWKacPYV1eet0zHillN/4pQ9eRFKAvsBRA7SIyE0iki0i2Xl5ef4IxxWXnHwJgzoN4uGFD1NQUlD3BkopdZwcT/AikgjMAu7wuFlIFWPMVGNMhjEmo1WrVk6H4xoR4Zlzdcx4pZT/OJrgRSQaK7m/aYx518m6gsGpHU7lmj7X8MyyZ3TMeKWU45y8ikaAV4ENxphnnKon2Pxp2J8QER747AG3Q1FKhTgnW/ADgWuBYSKyyp5GOlhfUOjYpCP3nHEPb619iy9zv3Q7HKVUCJNAGrM8IyPDZGdnux2G44oOFZH6t1S6NO3CkuuWYP2zo5RS9SciK4wxGd7W6S9ZXZAYk8gfM//IstxlOma8UsoxmuBdMj59PH3a9NEx45VSjtEE7xIdM14p5TRN8C46u+vZXHDiBTpmvFLKEZrgXfaXc/7C/kP7mfjxRL1Jt1KqQWmCd1n3lt15NPNR3l77NlOWTHE7HKVUCNEEHwAeGPQAV/a8kgc+e4APv//Q7XCUUiFCE3wAEBFeG/Ua/dr141ezfqV3f1JKNQhN8AEiPjqeOVfNIT46novevog9B/a4HZJSKshpgg8gyUnJzLlqDrkFuVzx3ysoLS91OySlVBDTBB9g+if3Z+oFU1nw4wLu+t9dboejlApiUW4HoI42Ln0c3+7+lqeXPU3vNr256ZSb3A5JKRWEtAUfoJ48+0mGdxvObXNvY9HWRW6Ho5QKQprgA1RkRCRvXfoWJzQ7gUv/cyk5+3LcDkkpFWQ0wQewpnFNef/q9ymrKGPU26MoOlTkdkhKqSCiCT7AndjiRGZeNpO1u9cydvZYKkyF2yEppYKEJvggcO4J5/L0uU8ze+NsJmdNdjscpVSQ0KtogsTE0yfy7a5veWzRY/Rq3Ysrel7hdkhKqQCnLfggISK8dP5LDOg4gPFzxvPNjm/cDkkpFeA0wQeR2KhY3r3iXVrGt2TU26PYVbTL7ZCUUgFME3yQaZPYhveueo+9B/cyeuZoSspK3A5JKRWgNMEHob7t+jJt1DSW5S7jNx/9Rm8UopTyShN8kLq85+X8fsjvmbZqGs8tf87tcJRSAUivoglijwx9hLV5a7n7k7tJbZ7K+See73ZISqkAoi34IBYhEUy/eDrpbdO5eObFzFg9w+2QlFIBRBN8kEuMSWTB2AUM6TyEsXPG8ufFf9Y+eaUUoAk+JDSJa8K8MfMY03sMv1vwO2796FbKKsrcDksp5TLtgw8RMZExzBg9g45JHXliyRNsL9zOW5e+RUJMgtuhKaVcoi34ECIi/PnsP/PiyBf5aNNHDHtjGLv373Y7LKWUSzTBh6BbT72Vd694l293fcuAVwewee9mt0NSSrnAsQQvIq+JyG4RWetUHapmo7qPYsG4BeSX5HPGq2ewPHe52yEppfzMyRb8NGC4g/tXdeif3J+l1y0lKTaJzOmZvP/d+26HpJTyI8cSvDFmEbDXqf0r36S2SGXZ9cvo1boXo2eO5h/Z/3A7JKWUn7jeBy8iN4lItohk5+XluR1OSGqd0JqF4xYyotsIbvnoFh787EG9Vl6pBmDMkVOgcf0ySWPMVGAqQEZGRgAeotCQEJPAnKvmcOtHt/KnL/7EtoJtvHLRK8RExrgdWr2Ul0NhIRQUHJ7y8+HAASguhpIS69Fz3pdlpaVQUWHtv6Li8OT5vLZ5zz9wXx/rWubrfH32czxJSKTu55XLvD3Wts7b/uqzrFJ93wPPx/qU8VVNr7v6srZtYevW+u3bF64neOU/URFR/POCf9KpSSceXvgwO4p2MOuKWSTFJvk1DmOsxLx9++Fpz56jk7a3+aJjuO94bCzExR39WDnfqBE0aQIREYenyMj6zUfY/wvXJ4n5ss7X+frsp7Z9VKrpC6S258ebPOuKoaZllct9PfbH+yVU0zpfX7e3ZYmJ3l/X8dIEH2ZEhIeGPERyUjI3fnAjg18fzNxfzaVDUocG2X9ZGezceWTy9jbt3+99+8aNrWSblGRNTZtCp07WvOdyz/mkJEhI8J7EY2Jqb/EpFcrEqb5YEXkLGAq0BHYBjxhjXq1tm4yMDJOdne1IPOpon2z5hEv/cynN4prx4a8+pE+bPnVuYwzs3g2bNlnT999bj1u3Wol71y6r28JTdDS0bw8dOtQ8tWpltWIiXD8rpFRwEZEVxpgMr+sC6WSbJnj/W7VzFSPfHMnPB37mwcEP8sDgB4iJjOGXX45M4J7zBQWHt4+Kgq5doUuXmpN3y5aauJVySm0JXrtowpgxkHQgncfbbeDZDz9m8qxinixYT2x+T/btja4qJwIpKZCaCmecYT2mpsKJJ0LnzlaSV0oFHv3TDBOHDsGGDbBypTWtWmVNVmu8CXAlLdocpChxJfu6vM7g0W24fcR59O4RR9euVp+2Uiq4aIIPQQUFsHq1lcArk/m6dVaSB4iPh7Q0GDMG+vaF9HTo0QMSEhpRUNKLSfP/xd+z/8623BSmpk/l5NhzXHw1SqljpX3wQa6wEJYtg+zsw8l8s8fYYi1bWkm8ckpPt7pXIiNr3+/irYu54YMb+H7P94xLG8cz5z1D80bNnXwpSqljoCdZQ0heHixefHhaufLwVStdux5O4pWP7dsf+2WCxWXFPPb5Yzy55ElaxLfghREvcFmPyxC97lCpgKEJPoht3QqLFh1O6Bs3Wsvj4uD002HIEBg8GE491bpm3Amrdq7i+vev55sd3zDqpFG8dP5LtG/c3pnKlFL1ogk+SBhjnQhdvPhwUt+2zVrXpAkMHGgl8yFD4JRT/Hvis6yijL8u+yu/z/o9MZEx/OWcv3BDvxuIEL3+USk3aYIPYD/9BO++C599ZiX0PXus5W3bWsm8curdu+5+c3/YvHczN35wI1k5WQxNGcrLF75Mt+bd3A5LqbClCT7A7N4Ns2bBzJlWS90Yq/+8srtl8GDo1i1wf2JvjOGVb17h3k/vpaS8hD8M/QN3nXEXURF6UZZS/qYJPgDs3QuzZ1tJfcECawTC7t3hyiut6eST3Y6w/n4q/Inb5t7GnI1zSG2eyj0D7mFs2ljiouLcDk2psKEJ3iX5+fDee1ZS/+QTayCuE044nNR79w7cVrqvjDG8/937PLboMVbsWEGbhDZMOH0Ct2TcQrNGzdwOT6mQpwnej/bvhw8+sJL6vHnWWOOdOh1O6v36BX9S98YYQ1ZOFlOWTuHjzR+TEJ3Ajf1u5I7+d9C5aWe3w1MqZGmCd9jBg1Yyf/tt+PBD63n79nD55VZS798/NJN6TdbsWsNTS5/irbVvYYzhql5Xce+Ae0lrm+Z2aEqFHE3wDtm5E/72N/j73+GXX6whbyuT+qBBOoLitvxtPPvls0z9ZipFh4o494RzuW/AfQzrMkx/LKVUA9EE38A2boSnn4Y33rBu9TZ6NNxyCwwdqiMrevPLwV/454p/8tzy59hZtJO+bfty38D7uKzHZXrljVLHqbYEH+ZtTN8ZA198AaNGWVe8/OtfcN118N131iWPZ5+tyb0mzRo1Y9KgSeRMzOGVC1/hQOkBrp51Nal/S+Vvy//G/kM13N5JKXVctAVfh/JymDMHnnoKvvwSWrSA226zptat3Y4uOFWYCj747gP+svQvLNm2hOaNmnNN72sYmTqSM1PO1MsslaoH7aI5BgcPwrRp8Mwz1uiMXbvCXXfBr39tDberGsbSbUt5etnTzN00l+KyYhpFNSKzSyYju41kROoIujbr6naISgU0vaNTPfz8M7z4IrzwgjV/2mnwzjtWP3sgDBUQagZ0HMCAjgM4WHqQrJws5m2ex7zN85i7aS7MgxNbnMiIbiMY0W2Etu6Vqidtwdu2bLFa66+/brXeL7gA7r3XGjZAL/jwv817NzNv0zzmbp5LVk7WEa37yoR/QvMT3A5TKddpF00t1qyBxx+H//7XOkl6zTVw993WHY5UYKjeut+817qjSWrzVEZ0G8HI1JEM7DSQxJhElyNVyv80wXuxciU89pg1PkxSEtx6K0yYAO3a+aV6dRwqW/fzNs9jYc5CisuKAejcpDM9WvU4Yjq55ck0iWvicsRKOUcTvIevv7YS+wcfWDfIuOMOK7E302FTgtLB0oN8vvVzVvy0gvU/r2d93no2/ryxKukDdGjc4ajE36NVD70FoQoJmuCxLnF89FFrSIFmzawrYn77W+tGGiq0lFeUk7Mvh/V5VsKvTPwb8jawv/TwNfdtEtpUJfuUpim0TmhNq/hWtEpoVfUYH62XTKnAFtYJfskSK7F/8ol1Dfs991jdMUlJDVqNCgIVpoJt+dsOJ36P5F9QUuB1m/jo+KMTvz3vubxpXFMSohOIj44nISaB6IhoHY5B+UVYXib5+edWYl+wwBojZsoUaziBRD0PF7YiJILOTTvTuWlnRqSOqFpujKHwUCF5+/PIO5DH7v27q+arHg/ksbNoJ9/u+pa8A3lHdAF5EymRJMQkHJH046Pjj3weFV9VJi4qjrioOGKjYomNjK3xsbYy0ZHRREdEExmh1/MqS0gleGNg4UL4wx+sOyW1aWONGXPzzZCQ4HZ0KlCJCEmxSSTFJvl06aUxhv2l+4/4QsgvzudA6QH2l+63Hg/tP/J56f6qZXsO7jmqzKHyQw33ehBiImOqEn50ZLT13J6vaVlURBTRkdbjEZMc+dxbmQiJQDj2/1hEBEGs/YhU7c9zvrZ1kRGRREokURFRREbYj/Zzb8u8lalrio6MDrp7EIdEgjcGPv3UarEvWWIN1fvcc3DjjdCokdvRqVAjIiTGJJIYk0iXZl0aZJ8VpoKSshJKykuqHovLio9aVlJmL6+2rKS8hNLyUkorSqseD5UfOmLZoYpqz8sPVc0XlxVTVlFW61RaXnrUsnJT3iCvP1gI4jX5V375VH7xeHsEalzXKqEVS65b0uDxBn2Cz8+H4cOtk6jJydYvUK+/HuL0B48qiERIBI2iG9EoOrhaJMYYyk055RXHl+grTAUGgzGmar7CVGCMOWK+pnXlFeVVcVR+8VR9CVVb5q2M5/Kjvtgqjv5iO+qLrqK8Kv4jHu15wPt6+7FJrDNXewR9gk9Ksm6DN368NcXGuh2RUuFDRKq6cFTgcfRdEZHhwHNAJPCKMeaJhq/DGrpXKaXUkRw7YyAikcCLwAigB3C1iOgAAEop5SdOnhI+DdhsjPnBGHMIeBsY5WB9SimlPDiZ4DsA2zye59rLlFJK+YGTCd7bRbFH/WxWRG4SkWwRyc7Ly3MwHKWUCi9OJvhcoKPH82Tgp+qFjDFTjTEZxpiMVq1aORiOUkqFFycT/NdAqoh0EZEY4CrgfQfrU0op5cGxyySNMWUicjvwP6zLJF8zxqxzqj6llFJHcvQ6eGPMXGCuk3UopZTyLqCGCxaRPGCr23HUoCXws9tB1ELjOz4a3/HR+I7P8cTX2Rjj9QRmQCX4QCYi2TWNuRwINL7jo/EdH43v+DgVX3CNfamUUspnmuCVUipEaYL33VS3A6iDxnd8NL7jo/EdH0fi0z54pZQKUdqCV0qpEKUJXimlQpQmeA8i0lFEForIBhFZJyITvZQZKiL5IrLKnn7v5xhzRORbu+5sL+tFRJ4Xkc0iskZE+vkxtpM8jssqESkQkTuqlfHr8ROR10Rkt4is9VjWXEQ+FZFN9mOzGrYdLiLf2cdykh/j+4uIbLTfv9ki0rSGbWv9LDgY32QR2e7xHo6sYVu3jt9Mj9hyRGRVDdv64/h5zSl++wwaY3QyVfdNbAf0s+cbA98DPaqVGQp86GKMOUDLWtaPBOZhjebZH1juUpyRwE6sH2G4dvyAIUA/YK3HsinAJHt+EvBkDfFvAboCMcDq6p8FB+M7F4iy55/0Fp8vnwUH45sM3OPD++/K8au2/mng9y4eP685xV+fQW3BezDG7DDGfGPPFwIbCL4x7EcBbxjLl0BTEWnnQhxnAVuMMa7+MtkYswjYW23xKGC6PT8duNjLpn65YY23+IwxnxhjyuynX2KNxOqKGo6fL1w7fpVERIArgLcaul5f1ZJT/PIZ1ARfAxFJAfoCy72sPkNEVovIPBHp6d/IMMAnIrJCRG7ysj5QbrRyFTX/Ybl5/ADaGGN2gPUHCLT2UiZQjuN1WP+ReVPXZ8FJt9tdSK/V0L0QCMdvMLDLGLOphvV+PX7VcopfPoOa4L0QkURgFnCHMaag2upvsLod0oC/AXP8HN5AY0w/rHvd3iYiQ6qt9+lGK04Sa3joi4B3vKx2+/j5KhCO44NAGfBmDUXq+iw45e/ACUA6sAOrG6Q6148fcDW1t979dvzqyCk1buZlWb2OoSb4akQkGuuNeNMY82719caYAmNMkT0/F4gWkZb+is8Y85P9uBuYjfVvnCefbrTisBHAN8aYXdVXuH38bLsqu63sx91eyrh6HEVkHHABMMbYHbLV+fBZcIQxZpcxptwYUwG8XEO9bh+/KOASYGZNZfx1/GrIKX75DGqC92D32b0KbDDGPFNDmbZ2OUTkNKxjuMdP8SWISOPKeayTcWurFXsfGCuW/kB+5b+CflRjy8nN4+fhfWCcPT8OeM9LGdduWCMiw4H7gYuMMQdqKOPLZ8Gp+DzP6YyuoV63b/hzNrDRGJPrbaW/jl8tOcU/n0EnzyAH2wQMwvoXaA2wyp5GAr8BfmOXuR1Yh3VG+0tggB/j62rXu9qO4UF7uWd8AryIdfb9WyDDz8cwHithN/FY5trxw/qi2QGUYrWIrgdaAJ8Bm+zH5nbZ9sBcj21HYl31sKXyWPspvs1Yfa+Vn8F/VI+vps+Cn+KbYX+21mAlnHaBdPzs5dMqP3MeZd04fjXlFL98BnWoAqWUClHaRaOUUiFKE7xSSoUoTfBKKRWiNMErpVSI0gSvlFIhShO8CnkiUi5HjnLZYCMbikiK50iGSgWSKLcDUMoPDhpj0t0OQil/0xa8Clv2eOBPishX9tTNXt5ZRD6zB9P6TEQ62cvbiDU++2p7GmDvKlJEXrbH+/5ERBrZ5SeIyHp7P2+79DJVGNMEr8JBo2pdNFd6rCswxpwGvAA8ay97AWvI5T5YA309by9/HvjcWAOl9cP6BSRAKvCiMaYnsA+41F4+Cehr7+c3zrw0pWqmv2RVIU9EiowxiV6W5wDDjDE/2ANC7TTGtBCRn7F+fl9qL99hjGkpInlAsjGmxGMfKcCnxphU+/n9QLQx5o8i8jFQhDVi5hxjD7KmlL9oC16FO1PDfE1lvCnxmC/n8Lmt87HGBToFWGGPcKiU32iCV+HuSo/HZfb8UqyR+wDGAF/Y858BtwCISKSIJNW0UxGJADoaYxYC9wFNgaP+i1DKSdqiUOGgkRx54+WPjTGVl0rGishyrMbO1fayCcBrInIvkAf82l4+EZgqItdjtdRvwRrJ0JtI4F8i0gRrhM+/GmP2NdDrUcon2gevwpbdB59hjPnZ7ViUcoJ20SilVIjSFrxSSoUobcErpVSI0gSvlFIhShO8UkqFKE3wSikVojTBK6VUiPp/WeiXE8p5PLIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = model.history.history['loss']\n",
    "acc_train = model.history.history['accuracy']\n",
    "epochs = range(1,21)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, acc_train, 'b', label='Training accuracy')\n",
    "plt.title('Training loss and accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c2f6f98",
   "metadata": {},
   "source": [
    "## Text generation\n",
    "Now we generate a few sentences using a random seed word and a set of various diversity (temperatures) which controls the randomness of generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9738ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['now', 'now', 'and', 'were', 'not', 'speaking', 'and']\n",
      "['youre', 'the', 'lucky', 'one', 'but', 'can', 'you']\n",
      "['i', 'know', 'he', 'got', 'that', 'same', 'and']\n",
      "['a', 'of', 'the', 'smile', 'you', 'didnt', 'find']\n",
      "['in', 'the', 'angel', 'city', 'chasing', 'your', 'mind']\n",
      "['been', 'waiting', 'for', 'king', 'of', 'my', 'heart']\n",
      "['woods', 'yet', 'are', 'we', 'out', 'of', 'the']\n"
     ]
    }
   ],
   "source": [
    "seed_index = np.random.randint(len(model.X_train+model.X_test))\n",
    "seed = (model.X_train+model.X_test)[seed_index]\n",
    "\n",
    "for diversity in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    sentence = seed\n",
    "    \n",
    "    for i in range(100):\n",
    "        x_pred = np.zeros((1, model.MIN_SEQ))\n",
    "        for t, word in enumerate(sentence):\n",
    "            x_pred[0, t] = model.word_indices[word]\n",
    "        preds = model.model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = model.sample(preds, diversity)\n",
    "        next_word = model.indices_word[next_index]\n",
    "        sentence = sentence[1:]\n",
    "        sentence.append(next_word)\n",
    "    print(sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
